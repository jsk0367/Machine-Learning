{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5543a71c-321b-402b-837a-be63020fc75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9577c2-a884-4863-ab39-6339987cf5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a385ca-32ed-4b97-99ed-aa6579d46ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_pre.sample(frac=1)\n",
    "df_pre = pd.read_csv('data/wine.csv')\n",
    "df = df_pre.sample(frac=0.5)  # 전체 데이터에서 샘플을 가져온다. 1= 100%, 0.7 = 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636632a1-32c2-4949-b6e1-39325dd69926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: red wine, 0: white wine\n",
    "# 1과 0을 구분하는 회귀, 바이너리 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f8cbeb0-ecad-4d9c-89c3-426068da3c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values\n",
    "print(dataset.dtype)\n",
    "# 전체가 float 이므로 형변환 불필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201cb764-ac98-4355-bef9-e18e9f7f34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, :12]\n",
    "Y = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096e701d-a36a-44a8-aa28-baca7810ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59cfc710-1084-46fd-8332-1e479cb58a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e92464-7239-473e-acce-8d9a8af5aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 및 optimize 연걸\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff452ab0-9442-44ae-a808-1ed6ebbe8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR) :  # 같은 파일명이 존재하는지 확인\n",
    "    os.mkdir(MODEL_DIR)   # 모델 생성\n",
    "    \n",
    "\n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True) # 체크포인트 생성, 무엇을 체크할 것인지 지정(mointor)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100) \n",
    "# 상태가 좋아지지 않으면 100번까지 참고, 그래도 loss 값이 좋아지지 않으면 자동으로 정지. 만약 값이 좋아지면 그 순간부터 다시 0부터 카운드 한다. \n",
    "\n",
    "# monitor=val_loss : 무엇을 체크할 것인지 지정. val_loss 를 관찰하라는 뜻\n",
    "# verbose=1 : 중간 과정을 계속 출력하라\n",
    "# save_best_only=True : 모델이 향상될 때만 저장하라 \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c614216b-2e58-460a-9c37-ebc78f5d5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, Y, validation_split=0.2, epochs=3500, batch_size=500, verbose=0, callbacks=[checkpointer,early_stopping])\n",
    "\n",
    "# validation_split=0.2 : 20% 를 뗴어놓고, 80%만 훈련시킨 후, 나머지 20% 를 validate을 해주고, 그때마다 그 값을 나타내 보여달라\n",
    "# verbose=0 : 출력 값을 보이지 마라\n",
    "# print(\"Accuracy:  %.4f\" % (model.evaluate(X, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ffc72a-30c6-4e08-a9c3-cac6de4edbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78050, saving model to ./model\\01-0.7805.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78050 to 0.66274, saving model to ./model\\02-0.6627.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66274 to 0.49704, saving model to ./model\\03-0.4970.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49704 to 0.46861, saving model to ./model\\04-0.4686.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.46861 to 0.37958, saving model to ./model\\05-0.3796.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.37958 to 0.37297, saving model to ./model\\06-0.3730.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37297 to 0.33296, saving model to ./model\\07-0.3330.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33296 to 0.31879, saving model to ./model\\08-0.3188.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31879 to 0.29468, saving model to ./model\\09-0.2947.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.29468 to 0.28704, saving model to ./model\\10-0.2870.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.28704 to 0.27127, saving model to ./model\\11-0.2713.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27127 to 0.26283, saving model to ./model\\12-0.2628.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.26283 to 0.25507, saving model to ./model\\13-0.2551.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.25507 to 0.24914, saving model to ./model\\14-0.2491.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.24914 to 0.24085, saving model to ./model\\15-0.2409.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24085 to 0.23495, saving model to ./model\\16-0.2350.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.23495 to 0.23190, saving model to ./model\\17-0.2319.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23190 to 0.22900, saving model to ./model\\18-0.2290.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.22900 to 0.22616, saving model to ./model\\19-0.2262.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22616 to 0.22424, saving model to ./model\\20-0.2242.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22424 to 0.22260, saving model to ./model\\21-0.2226.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22260 to 0.22185, saving model to ./model\\22-0.2219.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22185 to 0.21954, saving model to ./model\\23-0.2195.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.21954 to 0.21803, saving model to ./model\\24-0.2180.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21803 to 0.21674, saving model to ./model\\25-0.2167.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21674 to 0.21566, saving model to ./model\\26-0.2157.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21566 to 0.21438, saving model to ./model\\27-0.2144.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21438 to 0.21295, saving model to ./model\\28-0.2130.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.21295 to 0.21207, saving model to ./model\\29-0.2121.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21207 to 0.21182, saving model to ./model\\30-0.2118.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21182 to 0.21021, saving model to ./model\\31-0.2102.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.21021 to 0.20945, saving model to ./model\\32-0.2094.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.20945 to 0.20712, saving model to ./model\\33-0.2071.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20712 to 0.20493, saving model to ./model\\34-0.2049.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.20493 to 0.20350, saving model to ./model\\35-0.2035.hdf5\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.20350 to 0.20274, saving model to ./model\\36-0.2027.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.20274 to 0.19979, saving model to ./model\\37-0.1998.hdf5\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.19979 to 0.19868, saving model to ./model\\38-0.1987.hdf5\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.19868 to 0.19803, saving model to ./model\\39-0.1980.hdf5\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.19803 to 0.19715, saving model to ./model\\40-0.1972.hdf5\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.19715 to 0.19519, saving model to ./model\\41-0.1952.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.19519 to 0.19400, saving model to ./model\\42-0.1940.hdf5\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.19400\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.19400 to 0.19338, saving model to ./model\\44-0.1934.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.19338 to 0.19142, saving model to ./model\\45-0.1914.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.19142 to 0.19007, saving model to ./model\\46-0.1901.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.19007 to 0.18960, saving model to ./model\\47-0.1896.hdf5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.18960\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.18960\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.18960 to 0.18712, saving model to ./model\\50-0.1871.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.18712 to 0.18631, saving model to ./model\\51-0.1863.hdf5\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.18631 to 0.18581, saving model to ./model\\52-0.1858.hdf5\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.18581 to 0.18509, saving model to ./model\\53-0.1851.hdf5\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.18509 to 0.18420, saving model to ./model\\54-0.1842.hdf5\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.18420\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.18420 to 0.18327, saving model to ./model\\56-0.1833.hdf5\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.18327 to 0.18229, saving model to ./model\\57-0.1823.hdf5\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.18229 to 0.18096, saving model to ./model\\58-0.1810.hdf5\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.18096 to 0.18037, saving model to ./model\\59-0.1804.hdf5\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.18037\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.18037 to 0.17962, saving model to ./model\\61-0.1796.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.17962 to 0.17876, saving model to ./model\\62-0.1788.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.17876 to 0.17781, saving model to ./model\\63-0.1778.hdf5\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.17781 to 0.17734, saving model to ./model\\64-0.1773.hdf5\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.17734 to 0.17682, saving model to ./model\\65-0.1768.hdf5\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.17682 to 0.17585, saving model to ./model\\66-0.1759.hdf5\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.17585 to 0.17536, saving model to ./model\\67-0.1754.hdf5\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.17536 to 0.17451, saving model to ./model\\68-0.1745.hdf5\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.17451 to 0.17416, saving model to ./model\\69-0.1742.hdf5\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.17416 to 0.17397, saving model to ./model\\70-0.1740.hdf5\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.17397 to 0.17278, saving model to ./model\\71-0.1728.hdf5\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.17278 to 0.17244, saving model to ./model\\72-0.1724.hdf5\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.17244\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.17244 to 0.17079, saving model to ./model\\74-0.1708.hdf5\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.17079 to 0.17022, saving model to ./model\\75-0.1702.hdf5\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.17022 to 0.17003, saving model to ./model\\76-0.1700.hdf5\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.17003 to 0.16885, saving model to ./model\\77-0.1688.hdf5\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.16885 to 0.16852, saving model to ./model\\78-0.1685.hdf5\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.16852 to 0.16763, saving model to ./model\\79-0.1676.hdf5\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.16763 to 0.16734, saving model to ./model\\80-0.1673.hdf5\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.16734 to 0.16647, saving model to ./model\\81-0.1665.hdf5\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.16647 to 0.16582, saving model to ./model\\82-0.1658.hdf5\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.16582 to 0.16539, saving model to ./model\\83-0.1654.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.16539 to 0.16465, saving model to ./model\\84-0.1647.hdf5\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.16465 to 0.16419, saving model to ./model\\85-0.1642.hdf5\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.16419 to 0.16364, saving model to ./model\\86-0.1636.hdf5\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.16364 to 0.16294, saving model to ./model\\87-0.1629.hdf5\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.16294 to 0.16249, saving model to ./model\\88-0.1625.hdf5\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.16249 to 0.16184, saving model to ./model\\89-0.1618.hdf5\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.16184 to 0.16130, saving model to ./model\\90-0.1613.hdf5\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.16130 to 0.16075, saving model to ./model\\91-0.1607.hdf5\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.16075 to 0.16000, saving model to ./model\\92-0.1600.hdf5\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.16000 to 0.15955, saving model to ./model\\93-0.1596.hdf5\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.15955 to 0.15879, saving model to ./model\\94-0.1588.hdf5\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.15879\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.15879 to 0.15762, saving model to ./model\\96-0.1576.hdf5\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.15762 to 0.15705, saving model to ./model\\97-0.1570.hdf5\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.15705 to 0.15650, saving model to ./model\\98-0.1565.hdf5\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.15650 to 0.15612, saving model to ./model\\99-0.1561.hdf5\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.15612 to 0.15544, saving model to ./model\\100-0.1554.hdf5\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.15544 to 0.15497, saving model to ./model\\101-0.1550.hdf5\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.15497\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.15497 to 0.15407, saving model to ./model\\103-0.1541.hdf5\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.15407 to 0.15346, saving model to ./model\\104-0.1535.hdf5\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.15346 to 0.15312, saving model to ./model\\105-0.1531.hdf5\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.15312 to 0.15240, saving model to ./model\\106-0.1524.hdf5\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.15240\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.15240 to 0.15051, saving model to ./model\\108-0.1505.hdf5\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.15051 to 0.14938, saving model to ./model\\109-0.1494.hdf5\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.14938 to 0.14879, saving model to ./model\\110-0.1488.hdf5\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.14879 to 0.14791, saving model to ./model\\111-0.1479.hdf5\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.14791 to 0.14666, saving model to ./model\\112-0.1467.hdf5\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.14666 to 0.14587, saving model to ./model\\113-0.1459.hdf5\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.14587\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.14587 to 0.14424, saving model to ./model\\115-0.1442.hdf5\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.14424\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.14424 to 0.14227, saving model to ./model\\117-0.1423.hdf5\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.14227 to 0.14155, saving model to ./model\\118-0.1416.hdf5\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.14155 to 0.14055, saving model to ./model\\119-0.1406.hdf5\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.14055\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.14055 to 0.13911, saving model to ./model\\121-0.1391.hdf5\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.13911 to 0.13823, saving model to ./model\\122-0.1382.hdf5\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.13823 to 0.13800, saving model to ./model\\123-0.1380.hdf5\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.13800 to 0.13760, saving model to ./model\\124-0.1376.hdf5\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.13760 to 0.13621, saving model to ./model\\125-0.1362.hdf5\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.13621\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.13621 to 0.13447, saving model to ./model\\127-0.1345.hdf5\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.13447 to 0.13440, saving model to ./model\\128-0.1344.hdf5\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.13440 to 0.13348, saving model to ./model\\129-0.1335.hdf5\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.13348 to 0.13230, saving model to ./model\\130-0.1323.hdf5\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.13230 to 0.13166, saving model to ./model\\131-0.1317.hdf5\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.13166\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.13166 to 0.13039, saving model to ./model\\133-0.1304.hdf5\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.13039 to 0.13005, saving model to ./model\\134-0.1301.hdf5\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.13005 to 0.12938, saving model to ./model\\135-0.1294.hdf5\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.12938 to 0.12839, saving model to ./model\\136-0.1284.hdf5\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.12839 to 0.12799, saving model to ./model\\137-0.1280.hdf5\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.12799 to 0.12728, saving model to ./model\\138-0.1273.hdf5\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.12728 to 0.12724, saving model to ./model\\139-0.1272.hdf5\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.12724 to 0.12680, saving model to ./model\\140-0.1268.hdf5\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.12680\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.12680 to 0.12523, saving model to ./model\\142-0.1252.hdf5\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.12523 to 0.12473, saving model to ./model\\143-0.1247.hdf5\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.12473 to 0.12380, saving model to ./model\\144-0.1238.hdf5\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.12380 to 0.12344, saving model to ./model\\145-0.1234.hdf5\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.12344 to 0.12274, saving model to ./model\\146-0.1227.hdf5\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.12274 to 0.12265, saving model to ./model\\147-0.1227.hdf5\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.12265 to 0.12204, saving model to ./model\\148-0.1220.hdf5\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.12204 to 0.12161, saving model to ./model\\149-0.1216.hdf5\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.12161 to 0.12065, saving model to ./model\\150-0.1206.hdf5\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.12065 to 0.12048, saving model to ./model\\151-0.1205.hdf5\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.12048 to 0.11954, saving model to ./model\\152-0.1195.hdf5\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.11954 to 0.11916, saving model to ./model\\153-0.1192.hdf5\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.11916\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.11916 to 0.11878, saving model to ./model\\155-0.1188.hdf5\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.11878\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.11878 to 0.11720, saving model to ./model\\157-0.1172.hdf5\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.11720 to 0.11665, saving model to ./model\\158-0.1166.hdf5\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.11665 to 0.11649, saving model to ./model\\159-0.1165.hdf5\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.11649\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.11649\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.11649 to 0.11554, saving model to ./model\\162-0.1155.hdf5\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.11554 to 0.11476, saving model to ./model\\163-0.1148.hdf5\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.11476 to 0.11420, saving model to ./model\\164-0.1142.hdf5\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.11420 to 0.11354, saving model to ./model\\165-0.1135.hdf5\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.11354\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.11354 to 0.11299, saving model to ./model\\167-0.1130.hdf5\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.11299 to 0.11258, saving model to ./model\\168-0.1126.hdf5\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.11258 to 0.11246, saving model to ./model\\169-0.1125.hdf5\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.11246 to 0.11162, saving model to ./model\\170-0.1116.hdf5\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.11162 to 0.11126, saving model to ./model\\171-0.1113.hdf5\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.11126 to 0.11108, saving model to ./model\\172-0.1111.hdf5\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.11108 to 0.11096, saving model to ./model\\173-0.1110.hdf5\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.11096 to 0.11071, saving model to ./model\\174-0.1107.hdf5\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.11071 to 0.11042, saving model to ./model\\175-0.1104.hdf5\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.11042 to 0.10932, saving model to ./model\\176-0.1093.hdf5\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.10932\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.10932 to 0.10868, saving model to ./model\\178-0.1087.hdf5\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.10868 to 0.10835, saving model to ./model\\179-0.1084.hdf5\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.10835 to 0.10800, saving model to ./model\\180-0.1080.hdf5\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.10800 to 0.10787, saving model to ./model\\181-0.1079.hdf5\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.10787 to 0.10740, saving model to ./model\\182-0.1074.hdf5\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.10740 to 0.10713, saving model to ./model\\183-0.1071.hdf5\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.10713 to 0.10686, saving model to ./model\\184-0.1069.hdf5\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.10686 to 0.10623, saving model to ./model\\185-0.1062.hdf5\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.10623\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.10623\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.10623\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.10623 to 0.10592, saving model to ./model\\189-0.1059.hdf5\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.10592\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.10592 to 0.10440, saving model to ./model\\191-0.1044.hdf5\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.10440 to 0.10416, saving model to ./model\\192-0.1042.hdf5\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.10416\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.10416\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.10416\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.10416 to 0.10326, saving model to ./model\\196-0.1033.hdf5\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.10326 to 0.10279, saving model to ./model\\197-0.1028.hdf5\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.10279 to 0.10230, saving model to ./model\\198-0.1023.hdf5\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.10230 to 0.10212, saving model to ./model\\199-0.1021.hdf5\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.10212\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.10212 to 0.10185, saving model to ./model\\201-0.1019.hdf5\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.10185 to 0.10170, saving model to ./model\\202-0.1017.hdf5\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.10170 to 0.10159, saving model to ./model\\203-0.1016.hdf5\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.10159\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.10159\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.10159\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.10159\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.10159 to 0.10093, saving model to ./model\\208-0.1009.hdf5\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.10093\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.10093\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.10093\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.10093 to 0.09905, saving model to ./model\\212-0.0990.hdf5\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.09905 to 0.09881, saving model to ./model\\213-0.0988.hdf5\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.09881 to 0.09876, saving model to ./model\\214-0.0988.hdf5\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.09876\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.09876 to 0.09807, saving model to ./model\\216-0.0981.hdf5\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.09807 to 0.09802, saving model to ./model\\217-0.0980.hdf5\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.09802\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.09802 to 0.09725, saving model to ./model\\219-0.0972.hdf5\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.09725\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.09725 to 0.09720, saving model to ./model\\221-0.0972.hdf5\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.09720\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.09720 to 0.09609, saving model to ./model\\223-0.0961.hdf5\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.09609\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.09609\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.09609 to 0.09600, saving model to ./model\\226-0.0960.hdf5\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.09600\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.09600 to 0.09558, saving model to ./model\\228-0.0956.hdf5\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.09558 to 0.09545, saving model to ./model\\229-0.0954.hdf5\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.09545\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.09545\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.09545\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.09545\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.09545\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.09545\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.09545 to 0.09467, saving model to ./model\\236-0.0947.hdf5\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.09467 to 0.09374, saving model to ./model\\237-0.0937.hdf5\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.09374 to 0.09340, saving model to ./model\\238-0.0934.hdf5\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.09340 to 0.09322, saving model to ./model\\239-0.0932.hdf5\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.09322 to 0.09259, saving model to ./model\\240-0.0926.hdf5\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.09259 to 0.09223, saving model to ./model\\241-0.0922.hdf5\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.09223 to 0.09193, saving model to ./model\\242-0.0919.hdf5\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.09193\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.09193\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.09193\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.09193\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.09193\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.09193\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.09193 to 0.09092, saving model to ./model\\249-0.0909.hdf5\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.09092\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.09092 to 0.09031, saving model to ./model\\251-0.0903.hdf5\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.09031\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.09031\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.09031\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.09031\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.09031 to 0.08966, saving model to ./model\\256-0.0897.hdf5\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.08966 to 0.08922, saving model to ./model\\257-0.0892.hdf5\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.08922\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.08922 to 0.08909, saving model to ./model\\259-0.0891.hdf5\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.08909\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.08909 to 0.08862, saving model to ./model\\261-0.0886.hdf5\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.08862\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.08862 to 0.08855, saving model to ./model\\263-0.0886.hdf5\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.08855\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.08855 to 0.08757, saving model to ./model\\265-0.0876.hdf5\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.08757\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.08757\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.08757\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.08757 to 0.08740, saving model to ./model\\269-0.0874.hdf5\n",
      "\n",
      "Epoch 00270: val_loss improved from 0.08740 to 0.08723, saving model to ./model\\270-0.0872.hdf5\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.08723 to 0.08644, saving model to ./model\\271-0.0864.hdf5\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.08644\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.08644 to 0.08599, saving model to ./model\\273-0.0860.hdf5\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.08599\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.08599\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.08599\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.08599\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.08599 to 0.08570, saving model to ./model\\278-0.0857.hdf5\n",
      "\n",
      "Epoch 00279: val_loss improved from 0.08570 to 0.08532, saving model to ./model\\279-0.0853.hdf5\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.08532\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.08532\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.08532\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.08532\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.08532\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.08532 to 0.08399, saving model to ./model\\285-0.0840.hdf5\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.08399 to 0.08390, saving model to ./model\\286-0.0839.hdf5\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.08390 to 0.08381, saving model to ./model\\287-0.0838.hdf5\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.08381\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.08381\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.08381\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.08381\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.08381 to 0.08317, saving model to ./model\\292-0.0832.hdf5\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.08317 to 0.08314, saving model to ./model\\293-0.0831.hdf5\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.08314\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.08314\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.08314\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.08314\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.08314\n",
      "\n",
      "Epoch 00299: val_loss improved from 0.08314 to 0.08248, saving model to ./model\\299-0.0825.hdf5\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.08248 to 0.08195, saving model to ./model\\300-0.0819.hdf5\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.08195\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.08195\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.08195\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.08195\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.08195\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.08195 to 0.08107, saving model to ./model\\306-0.0811.hdf5\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.08107\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.08107\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.08107\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.08107\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.08107\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.08107\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.08107\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.08107\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.08107 to 0.08096, saving model to ./model\\315-0.0810.hdf5\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.08096\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.08096\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.08096 to 0.07997, saving model to ./model\\318-0.0800.hdf5\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.07997\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.07997\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.07997\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.07997 to 0.07851, saving model to ./model\\322-0.0785.hdf5\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.07851\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.07851\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.07851\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.07851 to 0.07846, saving model to ./model\\326-0.0785.hdf5\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.07846\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.07846\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.07846\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.07846\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.07846\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.07846\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.07846\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.07846\n",
      "\n",
      "Epoch 00335: val_loss improved from 0.07846 to 0.07826, saving model to ./model\\335-0.0783.hdf5\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.07826 to 0.07765, saving model to ./model\\336-0.0776.hdf5\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.07765\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.07765\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.07765\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.07765\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.07765 to 0.07762, saving model to ./model\\341-0.0776.hdf5\n",
      "\n",
      "Epoch 00342: val_loss improved from 0.07762 to 0.07757, saving model to ./model\\342-0.0776.hdf5\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.07757\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.07757\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.07757\n",
      "\n",
      "Epoch 00346: val_loss improved from 0.07757 to 0.07637, saving model to ./model\\346-0.0764.hdf5\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.07637\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.07637\n",
      "\n",
      "Epoch 00349: val_loss improved from 0.07637 to 0.07635, saving model to ./model\\349-0.0763.hdf5\n",
      "\n",
      "Epoch 00350: val_loss improved from 0.07635 to 0.07629, saving model to ./model\\350-0.0763.hdf5\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.07629\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.07629\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.07629\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.07629\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.07629\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.07629\n",
      "\n",
      "Epoch 00357: val_loss improved from 0.07629 to 0.07542, saving model to ./model\\357-0.0754.hdf5\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.07542\n",
      "\n",
      "Epoch 00371: val_loss improved from 0.07542 to 0.07494, saving model to ./model\\371-0.0749.hdf5\n",
      "\n",
      "Epoch 00372: val_loss improved from 0.07494 to 0.07418, saving model to ./model\\372-0.0742.hdf5\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.07418\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.07418\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.07418\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.07418\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.07418\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.07418\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.07418\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.07418 to 0.07368, saving model to ./model\\380-0.0737.hdf5\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.07368\n",
      "\n",
      "Epoch 00382: val_loss improved from 0.07368 to 0.07319, saving model to ./model\\382-0.0732.hdf5\n",
      "\n",
      "Epoch 00383: val_loss improved from 0.07319 to 0.07293, saving model to ./model\\383-0.0729.hdf5\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.07293\n",
      "\n",
      "Epoch 00385: val_loss improved from 0.07293 to 0.07259, saving model to ./model\\385-0.0726.hdf5\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.07259\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.07259\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.07259\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.07259\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.07259\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.07259\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.07259\n",
      "\n",
      "Epoch 00393: val_loss improved from 0.07259 to 0.07248, saving model to ./model\\393-0.0725.hdf5\n",
      "\n",
      "Epoch 00394: val_loss improved from 0.07248 to 0.07211, saving model to ./model\\394-0.0721.hdf5\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.07211 to 0.07206, saving model to ./model\\395-0.0721.hdf5\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00401: val_loss improved from 0.07206 to 0.07164, saving model to ./model\\401-0.0716.hdf5\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.07164\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.07164\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.07164\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.07164\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.07164\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.07164\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.07164\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.07164\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.07164\n",
      "\n",
      "Epoch 00411: val_loss improved from 0.07164 to 0.07137, saving model to ./model\\411-0.0714.hdf5\n",
      "\n",
      "Epoch 00412: val_loss improved from 0.07137 to 0.07128, saving model to ./model\\412-0.0713.hdf5\n",
      "\n",
      "Epoch 00413: val_loss improved from 0.07128 to 0.07124, saving model to ./model\\413-0.0712.hdf5\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.07124\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.07124\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.07124\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.07124\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.07124\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.07124\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.07124\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.07124\n",
      "\n",
      "Epoch 00422: val_loss improved from 0.07124 to 0.07100, saving model to ./model\\422-0.0710.hdf5\n",
      "\n",
      "Epoch 00423: val_loss improved from 0.07100 to 0.07084, saving model to ./model\\423-0.0708.hdf5\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.07084\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.07084\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.07084\n",
      "\n",
      "Epoch 00427: val_loss improved from 0.07084 to 0.07082, saving model to ./model\\427-0.0708.hdf5\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.07082\n",
      "\n",
      "Epoch 00429: val_loss improved from 0.07082 to 0.07046, saving model to ./model\\429-0.0705.hdf5\n",
      "\n",
      "Epoch 00430: val_loss improved from 0.07046 to 0.07035, saving model to ./model\\430-0.0704.hdf5\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.07035\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.07035\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.07035\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.07035\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.07035\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.07035\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.07035\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.07035\n",
      "\n",
      "Epoch 00439: val_loss improved from 0.07035 to 0.06992, saving model to ./model\\439-0.0699.hdf5\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00452: val_loss improved from 0.06992 to 0.06991, saving model to ./model\\452-0.0699.hdf5\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.06991\n",
      "\n",
      "Epoch 00454: val_loss improved from 0.06991 to 0.06960, saving model to ./model\\454-0.0696.hdf5\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.06960\n",
      "\n",
      "Epoch 00481: val_loss improved from 0.06960 to 0.06944, saving model to ./model\\481-0.0694.hdf5\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.06944\n",
      "\n",
      "Epoch 00483: val_loss improved from 0.06944 to 0.06897, saving model to ./model\\483-0.0690.hdf5\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.06897\n",
      "\n",
      "Epoch 00497: val_loss improved from 0.06897 to 0.06885, saving model to ./model\\497-0.0688.hdf5\n",
      "\n",
      "Epoch 00498: val_loss improved from 0.06885 to 0.06866, saving model to ./model\\498-0.0687.hdf5\n",
      "\n",
      "Epoch 00499: val_loss improved from 0.06866 to 0.06859, saving model to ./model\\499-0.0686.hdf5\n",
      "\n",
      "Epoch 00500: val_loss improved from 0.06859 to 0.06840, saving model to ./model\\500-0.0684.hdf5\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00515: val_loss improved from 0.06840 to 0.06838, saving model to ./model\\515-0.0684.hdf5\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.06838\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.06838\n",
      "\n",
      "Epoch 00518: val_loss improved from 0.06838 to 0.06837, saving model to ./model\\518-0.0684.hdf5\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.06837\n",
      "\n",
      "Epoch 00520: val_loss improved from 0.06837 to 0.06823, saving model to ./model\\520-0.0682.hdf5\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.06823\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.06823\n",
      "\n",
      "Epoch 00523: val_loss improved from 0.06823 to 0.06806, saving model to ./model\\523-0.0681.hdf5\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.06806\n",
      "\n",
      "Epoch 00534: val_loss improved from 0.06806 to 0.06756, saving model to ./model\\534-0.0676.hdf5\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.06756\n",
      "\n",
      "Epoch 00562: val_loss improved from 0.06756 to 0.06719, saving model to ./model\\562-0.0672.hdf5\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.06719\n",
      "\n",
      "Epoch 00602: val_loss improved from 0.06719 to 0.06709, saving model to ./model\\602-0.0671.hdf5\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.06709\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.06709\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.06709\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.06709\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.06709\n",
      "\n",
      "Epoch 00608: val_loss improved from 0.06709 to 0.06707, saving model to ./model\\608-0.0671.hdf5\n",
      "\n",
      "Epoch 00609: val_loss improved from 0.06707 to 0.06690, saving model to ./model\\609-0.0669.hdf5\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00618: val_loss improved from 0.06690 to 0.06686, saving model to ./model\\618-0.0669.hdf5\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.06686\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.06686\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X,Y, validation_split=0.33,\n",
    "                    epochs=3500, batch_size=500, verbose=0, callbacks=[checkpointer,early_stopping])\n",
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, 'o', c='red', markersize=3)\n",
    "plt.plot(x_len, y_acc, 'o', c='blue', markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd84cf9-80bf-4c0a-b0a7-d84e3cfe926a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17906b55-172c-4b8c-b1c9-43cce9a08b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
