{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261632e2-ad21-4455-ae4b-d41c3c845bfd",
   "metadata": {},
   "source": [
    "## Bag of Words(Bow)\n",
    "- 단어의 순서는 고려하지 않고 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 방법\n",
    "- 우선, 각 단어에 고유한 정수 인덱스를 부여\n",
    "- 각 인덱스의 위치에 단어 토큰의 동장 횟수를 기록한 벡터를 만듬\n",
    "- scikit-learn의 Countvectorizer를 이용하여 간단히 Bow를 구성할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a04b5d-dd11-4b31-98d3-48fa5f9b3059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0ea2717-1d23-43e1-b1e9-d9fd4183d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐뭑지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "count_vectorizer =CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee0f846-6533-4960-ac39-7e2b17a18e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐뭑지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer.fit(text_data)\n",
    "print(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075f86e6-23df-4176-956b-4b5bbe8df50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[0]]\n",
    "print(count_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a287159f-1cd2-46a9-bfc0-0f9b7a605d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sentence = ['오늘 점심 맛없었어','내일 점심 또 그럴까']\n",
    "print(count_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910d62b-54bb-4d04-baf5-3577e56400f7",
   "metadata": {},
   "source": [
    "### 문서 단어 행렬(Document-Term Matrix, DTM)\n",
    "- 서로 다른 문서들의 BoW들을 결합한 표현 방법  \n",
    "- 다수의 문서에 등장하는 각 단어들의 빈도를 행렬로 표현한 것  \n",
    "- 문서1 : 호기심 많은 고양이  \n",
    "- 문서2 : 꼬리가 긴 고양이  \n",
    "- 문서3 : 호기심 많은 강아지  \n",
    "- 문서4 : 철수는 동물을 좋아해요 \n",
    "|      |강아지|고양이|긴|꼬리가|동물을|많은|좋아해요|철수는|호기심|\n",
    "|------|-----|-----|--|-----|-----|---|-------|-----|-----|\n",
    "|문서1  |  0  |  1  | 0|  0  |  0 | 1  |   0   |  0  |  1  |\n",
    "|문서2  |  0  |  1  |1|  1  |  0 | 0  |   0   |  0  |  0  |\n",
    "|문서3  |  1  |  0  |0|  0  |  0 | 1  |   0   |  0  |  1  |\n",
    "|문서4  |  0  |  0  |0|  0  |  1 | 0  |   1   |  1  |  0  |  \n",
    "- 각 문서에서 등장한 단어의 빈도를 행렬값으로 표시  \n",
    "- 문서들을 서로 비교할 수 있도록 수치화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e00ffc-d3d2-4bc3-82e3-b2eba54d017f",
   "metadata": {},
   "source": [
    "## 문서 단어 행렬의 한계\n",
    "1.희소 표현\n",
    "\n",
    "- one_hot encoding 방식의 벡터는 단어 집합의 크기가 벡터의 차원이 됨(대부분의 값이0)\n",
    "- 공간과 계산 리소스의 낭비\n",
    "\n",
    "2.단순 빈도수 기반 접근\n",
    "\n",
    "- 여러 문서에 등장하는 모든 단어에 대해서는 빈도수만을 사용하는 한계\n",
    "- 각 문서에는 중요한 단어와 불필요한 단어가 혼재되어 있음\n",
    "- DTM에 불용어와 중요한 단어에 대한 가중치를 부여하는 방법이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14966e3f-b522-400f-ad0a-1add8195f99f",
   "metadata": {},
   "source": [
    "TF-IDF(Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "- 단어의 빈도와 역 문서 빈도를 사용하여 DTM내의 각 단어들마다 중요한 정도의 가중치를 부여하는 방법  \n",
    "- 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰임  \n",
    "- TF-IDF 는 TF와 IDF를 곱한 값을 의미  \n",
    "- 문서를 d, 단어를 t, 문서의 총 개수를 n이라고 하면  \n",
    "1) tf(d, t): 특정 문서 d에서의 특정 단어 t의 등장 회수  \n",
    "2) df(t) : 특정 단어 t가 등장한 문서의 수  \n",
    "3) idf(d, t) : df(t)에 반비례하는 수  \n",
    "idf(d, t) = log(n / (1 + df(t)))\n",
    "- 총 문서의 수 n이 급격히 증가하게 되면 IDF의 값이 기하급수적으로 커지는 것을 방지하기 위해 log를 사용  \n",
    "- 특정 단어가 전체 문서에서 등장하지 않게 되는 경우 분모가 0이 되는 것을 방지하기 위해 1을 더함  \n",
    "- TF-IDF는 모든 문서에서 자주 등장하는 단어는 중요도가 낮다고 판단  \n",
    "- 특정 문서에서만 자주 등장하는 단어는 중요도가 높다고 판단  \n",
    "- TF-IDF 값이 낮으면 중요도가 낮다고 판단  \n",
    "- 예를 들어 영어에서 the 나 a와 같은 불용어의 경우 모든 문서에 자주 등장하기 때문에 이런 불용어들의 TF-IDF 값은 다른 단어에 비해서 낮아지게 됨  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52480888-3900-4204-a9b2-cec86d77f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03768ce2-9bfc-4e9d-a98c-ee2127790de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐뭑지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af35db22-738b-43bb-8a10-2395f13ac0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐뭑지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3605cb1-4ef0-4d93-b752-c500fc0788d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.43779123 0.         0.         0.55528266 0.\n",
      "  0.         0.43779123 0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[3]]\n",
    "print(tfidf_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "805988c2-7cbc-42ec-a06b-158cd399ed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57735027 0.         0.57735027 0.         0.         0.\n",
      "  0.57735027 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.52640543 0.         0.66767854\n",
      "  0.         0.52640543 0.         0.        ]\n",
      " [0.         0.52640543 0.         0.52640543 0.         0.\n",
      "  0.         0.         0.66767854 0.        ]\n",
      " [0.         0.43779123 0.         0.         0.55528266 0.\n",
      "  0.         0.43779123 0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.transform(text_data).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b466ed45-5854-44a9-b8b0-073cf115f2b0",
   "metadata": {},
   "source": [
    "- TF-IDF 값을  사용할 경우, 단순 횟수를 이용하는 것보다 각 단어의 특성을 좀 더 잘 반영할 수 있음\n",
    "- 모델에 적용할 때도 TfidfVectorizer를 사용하는 것이 일반적으로 더 좋은 결과를 만들어 냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44185d-0ce3-4895-b5e2-1688a89c2694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
